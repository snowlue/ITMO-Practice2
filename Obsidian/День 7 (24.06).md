Начали разработку ноды `slam_node` для реализации алгоритма [[ORB SLAM]]. Научились считывать изображение из топика `/camera/camera/color/image_raw`  и матрицы преобразования камеры realsense из `/camera/camera/color/camera_info`. Далее с помощью `opencv` задетектили Aruco-маркеры и нашли направления их осей, отобразили данные в `RViz`.  
![[Снимок экрана_20250624_115211 1.png]]

---
Оттачивали алгоритм [[AMCL]], а также изучали, как встроить данные с лидара и одометрию робота в `measurement_model` и `motion_model` соответственно. Пришли к выводу, что существующий алгоритм недостаточно хорош для этого, поэтому появилась необходимость в переписании и использовании нового решения.

Получили [новый документ](https://gitlab.u-angers.fr/cours/mobile_robotic_student/-/blob/master/documents/MCL/MCL.pdf), в котором описан ресемплинг и работа с картой, одометрия и сканами с лидара. В том же репозитории с документом имеется [шаблон MCL](https://gitlab.u-angers.fr/cours/mobile_robotic_student/-/tree/master/tp_mcl), который можно использовать для своей реализации.